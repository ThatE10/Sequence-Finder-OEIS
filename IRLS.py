import numpy as np
import scipy as sp
from scipy.linalg import hankel
import math

def ceil(R):
    return R


def hankel(s):
    return sp.linalg.hankel(s[:len(s) // 2 + 1], s[len(s) // 2:])


def P_omega(Y):
    omega = []
    for i, x in enumerate(Y):
        if not math.isnan(x):
            omega.append(i)
    return (np.eye(len(Y))[omega])


def weight_tilda(U, S, V, E, X, type_mean='harmonic'):
    # U, left singular vectors, matrix of size d_1 x rk
    # S, Sigma Values
    # V, right singular vectors, matrix of size d_2 x rk,
    # E is the smoothing parameter
    # X is the matrix we want to change using the weight operator

    S_ = np.maximum(S, E)
    [d1, rk] = np.shape(U)
    d2 = np.shape(V)[0]

    # print(S)
    # print(S_)
    R = min(len(U), len(V))

    H = np.zeros([rk, rk])
    D = np.zeros([rk, rk])

    # U = U[:,:R]
    # V = V[:,:R]
    """
    print(U.shape)
    print(S.shape)
    print(V.shape)
    print(X.shape)
    print(H.shape)
    print(D.shape)
    #"""

    ##################################
    # Building H
    # We assume R to be the size of the sigmas due to the size of the sequence being relatively small, we also set r ~ 2/4
    # meaing R must be larger then 2/4 and with sequences this means we will often have weird things...
    for i in range(rk):
        for j in range(rk):
            if type_mean == 'harmonic':
                H[i, j] = 2 * ((S[i] ** 2 + S[j] ** 2 + 2 * (E ** 2)) ** -1)
            elif type_mean == 'geometric':
                H[i, j] = (S_[i] ** -1) * (S_[j] ** -1)

    ##################################
    # Building D
    for i in range(rk):
        if type_mean == 'harmonic':
            D[i, i] = 2 * ((S[i] ** 2 + 2 * (E ** 2)) ** -1)
        elif type_mean == 'geometric':
            D[i, i] = (S_[i] ** -1) * (E ** -1)  # 2 * (( S[i]**2 + 2*(E**2))**-1)

    # print(U.shape,H.shape,U.T.shape,X.shape,V.shape,V.T.shape)
    L = U @ (H * (U.T @ X @ V)) @ V.T

    # M is the ...
    M = U @ D.T @ U.T @ X @ (np.eye(d2) - V @ V.T)

    # N is the ...
    # print(R,U.shape,U.T.shape,X.shape,V.shape,D.T.shape,V.T.shape)
    N = (np.eye(d1) - U @ U.T) @ X @ V @ D.T @ V.T

    # O is the ...
    O = (E ** -2) * ((np.eye(d1) - U @ U.T) @ X @ (np.eye(d2) - V @ V.T))

    return (L + M + N + O)


def hm_irls(data_vector, rank_estimate, max_iter=100, tol=1e-8, type_mean='harmonic'):
    """Runs an iteratively reweighted least squares algorithms for the recovery of incomplete linear recurrence sequences from partial data.
    Leverages low-rank property of underlying Hankel matrix.

    Parameters
    ----------
    data_vector :  numpy.array / list
        Incomplete sequence of total length n. Zero values correspond to missing data at respective index (potential todo: change to float("nan"))
    rank_estimate : int
        Target rank of Hankel matrix. Corresponds to order of linear recurrence relation.
    max_iter : int
        Maximum number of iterations.
    tol : float
        Tolerance parameter that governs the stopping criterion. Stopping criterion: Relative change of l2-norm smaller than tol.
    Returns
    -------
    x : numpy.array
        Reconstructed sequence.
    stats : dictionary
        Contains algorithmic statistics.
    """
    x = data_vector
    P = P_omega(x)
    x = [0 if (isinstance(num, float) or isinstance(num, int)) and math.isnan(num) else num for num in x]

    # The unpadded 0 vector of data
    y = x @ P.T

    r = rank_estimate  # true_rank_parameter

    n = len(x)
    m = len(y)
    # R = rank_estimate  : I got rid of this parameter as it is not necessary to formulate the IRLS algorithm

    U, S, Vt = np.linalg.svd(hankel(x))

    smoothing = [0] * (max_iter)
    smoothing[0] = S[0]

    weights = [0] * (max_iter)
    weights[0] = smoothing[0] * np.identity(n)
    ranks = []
    stats = dict()

    for f in range(1, max_iter):
        x_o = x.copy()
        # print(f)

        W = weights[f - 1]

        if np.linalg.det(W) != 0:
            W_i = np.linalg.inv(W)

        # We can simplify the following line to make it more computationally efficent by solving directly for z
        # x = W_i @ P.T @ (np.linalg.inv(P@W_i@P.T) @ y )
        # P @ W_i @ P.T * z = Y    => linalg.solve(P@W_i@P.T,y)

        # recalculate the data vector using a minimisation method & constraint (4
        x = W_i @ P.T @ (np.linalg.solve(P @ W_i @ P.T, y))

        # SVD of the Padded hankel data vector (5)
        U, S, Vt = np.linalg.svd(hankel(x))

        smoothing[f] = min(smoothing[f - 1], S[r])
        r_c = np.sum(S > smoothing[f])
        ranks.append(r_c)

        # Calculate each element in the weight matrix with
        # W_ij = e_i.T W @ e_j
        # => vec(e_i.hankel) @ vec(weight_tilda(e_j.hankel))
        W = np.zeros([n, n])

        for i in range(0, n):
            e_i = [0] * n
            e_i[i] = 1
            for j in range(0, n):
                e_j = [0] * n
                e_j[j] = 1
                W[i, j] = hankel(e_i).flatten() @ weight_tilda(U[:, :r_c], S, Vt[:r_c, :].T, smoothing[f], hankel(e_j),
                                                               type_mean=type_mean).flatten()
        weights[f] = W
        #print(np.round(x, 8))
        # Check stopping criterion: relativ l2-error < tol
        rel_chg = np.linalg.norm(x_o - x) / np.linalg.norm(x_o)
        #print(rel_chg)
        if f > 1 and rel_chg < tol:
            break
    """    
    for w in weights:
        print("\n\n\n")
        print(np.round(w,0))
    #for s in smoothing:
        #print("\n\n\n")
        #print(s)
    """
    stats['ranks'] = ranks
    stats['smoothing'] = smoothing[0:f]
    stats['k'] = f
    return x, stats
